services:
  # 1. Datenbank (bleibt wie es ist)
  rezept_db:
    image: postgres:15
    container_name: rezept_db
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: rezept_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: always

  # 2. KI (bleibt wie es ist)
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: rezept_ai
  #   # ... ports, volumes etc. ...
  #   environment:
  #     - OLLAMA_HOST=0.0.0.0
  #     # WICHTIG: Begrenze, wie viele Modelle gleichzeitig im RAM bleiben (default ist 5 min)
  #     - OLLAMA_KEEP_ALIVE=5m 
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 7G  # Hartes Limit: Mehr bekommt er nicht.
  #       reservations:
  #         memory: 4G  # Das garantiert er sich mindestens.
  #   restart: always

  # 3. NEU: Dein Backend Server
  backend:
    build:
      context: ./backend # Hier liegt das Dockerfile
      dockerfile: Dockerfile
    container_name: homechef_backend
    ports:
      - "3005:3000" # Von au√üen erreichbar auf Port 3000
    depends_on:
      - rezept_db
      - ollama
    environment:
      # Innerhalb von Docker nutzen wir die Container-Namen als Hostnamen!
      - DATABASE_URL=postgresql://user:password@rezept_db:5432/rezept_db?schema=public
      #- OLLAMA_URL=http://ollama:11434/api/generate
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    restart: always

volumes:
  postgres_data:
  ollama_data: